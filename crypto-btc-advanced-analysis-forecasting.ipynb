{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Cryptocurrency : Advanced Analysis & Forecasting","metadata":{"papermill":{"duration":0.132445,"end_time":"2022-05-24T12:30:02.708771","exception":false,"start_time":"2022-05-24T12:30:02.576326","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Import libraries\nimport random\nimport os\nimport numpy as np \nimport pandas as pd \nimport requests\nimport pandas_datareader as web\n\n# Date\nimport datetime as dt\nfrom datetime import date, timedelta, datetime\n\n# EDA\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import rcParams\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# FE\nfrom tsfresh import extract_features, select_features, extract_relevant_features\nfrom tsfresh.utilities.dataframe_functions import impute\nfrom sklearn.inspection import permutation_importance\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\n\n# Time Series - EDA and Modelling\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\n\n# Metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n\n# Modeling and preprocessing\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom prophet import Prophet\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"papermill":{"duration":13.959932,"end_time":"2022-05-24T12:30:18.084895","exception":false,"start_time":"2022-05-24T12:30:04.124963","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:18.842069Z","iopub.execute_input":"2022-05-26T02:45:18.842584Z","iopub.status.idle":"2022-05-26T02:45:31.692257Z","shell.execute_reply.started":"2022-05-26T02:45:18.842467Z","shell.execute_reply":"2022-05-26T02:45:31.691041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Automatic building ARIMA for Time Series\n!pip install pmdarima\nimport pmdarima as pm","metadata":{"_kg_hide-output":true,"papermill":{"duration":14.809239,"end_time":"2022-05-24T12:30:33.024434","exception":false,"start_time":"2022-05-24T12:30:18.215195","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:31.694737Z","iopub.execute_input":"2022-05-26T02:45:31.695496Z","iopub.status.idle":"2022-05-26T02:45:45.511991Z","shell.execute_reply.started":"2022-05-26T02:45:31.695446Z","shell.execute_reply":"2022-05-26T02:45:45.510811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random state\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nrandom_state = 42\nfix_all_seeds(random_state)","metadata":{"papermill":{"duration":0.143151,"end_time":"2022-05-24T12:30:33.30189","exception":false,"start_time":"2022-05-24T12:30:33.158739","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.51395Z","iopub.execute_input":"2022-05-26T02:45:45.514319Z","iopub.status.idle":"2022-05-26T02:45:45.521813Z","shell.execute_reply.started":"2022-05-26T02:45:45.514258Z","shell.execute_reply":"2022-05-26T02:45:45.520723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set main parameters\ncryptocurrency = 'BTC'\ntarget = 'Close'\nforecasting_days = 10  # forecasting_days > 1","metadata":{"papermill":{"duration":0.146281,"end_time":"2022-05-24T12:30:33.85259","exception":false,"start_time":"2022-05-24T12:30:33.706309","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.524476Z","iopub.execute_input":"2022-05-26T02:45:45.52526Z","iopub.status.idle":"2022-05-26T02:45:45.541394Z","shell.execute_reply.started":"2022-05-26T02:45:45.525208Z","shell.execute_reply":"2022-05-26T02:45:45.540677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set time interval of data for given cryptocurrency - the period of coronavirus in 2020-2021\ndate_start = dt.datetime(2020, 4, 1)\n# date_end = dt.datetime.now()\ndate_end = dt.datetime(2021, 12, 31)\nprint(f\"Time interval: from {date_start} to {date_end}\")","metadata":{"papermill":{"duration":0.147461,"end_time":"2022-05-24T12:30:34.419384","exception":false,"start_time":"2022-05-24T12:30:34.271923","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.542626Z","iopub.execute_input":"2022-05-26T02:45:45.543689Z","iopub.status.idle":"2022-05-26T02:45:45.556076Z","shell.execute_reply.started":"2022-05-26T02:45:45.543626Z","shell.execute_reply":"2022-05-26T02:45:45.555375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What type of model to use?\nis_Prophet = True   # or False - Facebook Prophet\nis_ARIMA = True     # or False - ARIMA and AutoARIMA\nis_other_ML = True  # or False - multi-factors models: trees, neural networks, etc.","metadata":{"papermill":{"duration":0.1497,"end_time":"2022-05-24T12:30:34.704905","exception":false,"start_time":"2022-05-24T12:30:34.555205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.557342Z","iopub.execute_input":"2022-05-26T02:45:45.558111Z","iopub.status.idle":"2022-05-26T02:45:45.572841Z","shell.execute_reply.started":"2022-05-26T02:45:45.558069Z","shell.execute_reply":"2022-05-26T02:45:45.571289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download information about cryptocurrencies\ndf_about = pd.read_csv(\"../input/forecasting-top-cryptocurrencies/about_top_cryptocurrencies_1B_information.csv\", sep=\";\")\ndisplay(df_about)","metadata":{"papermill":{"duration":0.196135,"end_time":"2022-05-24T12:30:35.319106","exception":false,"start_time":"2022-05-24T12:30:35.122971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.574603Z","iopub.execute_input":"2022-05-26T02:45:45.575226Z","iopub.status.idle":"2022-05-26T02:45:45.644751Z","shell.execute_reply.started":"2022-05-26T02:45:45.575185Z","shell.execute_reply":"2022-05-26T02:45:45.643646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_part_number(x):\n    # Get 1 - st, 2 - nd, 3 - rd, 4.. - th in the first, second, third, ...\n    if x==1:\n        return 'st'\n    elif x==2:\n        return 'nd'\n    elif x==3:\n        return 'rd'\n    else: return 'th'","metadata":{"papermill":{"duration":0.144021,"end_time":"2022-05-24T12:30:35.604764","exception":false,"start_time":"2022-05-24T12:30:35.460743","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.646251Z","iopub.execute_input":"2022-05-26T02:45:45.646524Z","iopub.status.idle":"2022-05-26T02:45:45.653037Z","shell.execute_reply.started":"2022-05-26T02:45:45.646489Z","shell.execute_reply":"2022-05-26T02:45:45.651844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rank_cryptocurrency(cryptocurrency):\n    # Get rank by Market Cap for code of the cryptocurrency\n    # Download the dataset from https://www.kaggle.com/datasets/vbmokin/forecasting-top-cryptocurrencies\n    \n    place = df_about.index[df_about['code'] == cryptocurrency].tolist()[0]\n    print(f\"{df_about.loc[place, 'name']} was {place+1}{get_part_number(place+1)}\",\n          \"among the world's cryptocurrencies by market capitalization (2022-04-11)\")\n    \n# Get rank by Market Cap of the cryptocurrency\nget_rank_cryptocurrency(cryptocurrency)","metadata":{"papermill":{"duration":0.157326,"end_time":"2022-05-24T12:30:35.897345","exception":false,"start_time":"2022-05-24T12:30:35.740019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.65476Z","iopub.execute_input":"2022-05-26T02:45:45.6556Z","iopub.status.idle":"2022-05-26T02:45:45.674199Z","shell.execute_reply.started":"2022-05-26T02:45:45.655554Z","shell.execute_reply":"2022-05-26T02:45:45.67335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(cryptocurrency, date_start, date_end=None):\n    # Get data for given cryptocurrency in USD from Yahoo.finance and https://coinmarketcap.com/\n    # date_end = None means that the date_end is the current day\n    \n    if date_end is None:\n        date_end = dt.datetime.now()\n    df = web.DataReader(f'{cryptocurrency}-USD', 'yahoo', date_start, date_end)\n    \n    return df\n\n# Download data of the cryptocurrency via API\ndf = get_data(cryptocurrency, date_start, date_end)\ndf","metadata":{"papermill":{"duration":1.481439,"end_time":"2022-05-24T12:30:37.520875","exception":false,"start_time":"2022-05-24T12:30:36.039436","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:45.677693Z","iopub.execute_input":"2022-05-26T02:45:45.678088Z","iopub.status.idle":"2022-05-26T02:45:46.92995Z","shell.execute_reply.started":"2022-05-26T02:45:45.678053Z","shell.execute_reply":"2022-05-26T02:45:46.928658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation coefficients\ndf.corr()","metadata":{"papermill":{"duration":0.167405,"end_time":"2022-05-24T12:30:37.827295","exception":false,"start_time":"2022-05-24T12:30:37.65989","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:46.931511Z","iopub.execute_input":"2022-05-26T02:45:46.931747Z","iopub.status.idle":"2022-05-26T02:45:46.950076Z","shell.execute_reply.started":"2022-05-26T02:45:46.931719Z","shell.execute_reply":"2022-05-26T02:45:46.949023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation coefficients\ndf.corr()['Close']","metadata":{"papermill":{"duration":0.164383,"end_time":"2022-05-24T12:30:38.128402","exception":false,"start_time":"2022-05-24T12:30:37.964019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:46.951984Z","iopub.execute_input":"2022-05-26T02:45:46.952277Z","iopub.status.idle":"2022-05-26T02:45:46.965677Z","shell.execute_reply.started":"2022-05-26T02:45:46.952242Z","shell.execute_reply":"2022-05-26T02:45:46.964577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns = [\"Adj Close\"])\ndf","metadata":{"papermill":{"duration":0.160392,"end_time":"2022-05-24T12:30:38.425378","exception":false,"start_time":"2022-05-24T12:30:38.264986","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:46.967082Z","iopub.execute_input":"2022-05-26T02:45:46.967451Z","iopub.status.idle":"2022-05-26T02:45:46.988055Z","shell.execute_reply.started":"2022-05-26T02:45:46.96741Z","shell.execute_reply":"2022-05-26T02:45:46.98704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Market Cap\ncrypto = pd.Series(df_about.market_cap.head(20).tolist(), index=df_about.name.head(20).tolist(), name=\"Капіталізація ринка\")\ncrypto.plot.pie(figsize=(10, 10))","metadata":{"papermill":{"duration":0.472086,"end_time":"2022-05-24T12:30:39.594811","exception":false,"start_time":"2022-05-24T12:30:39.122725","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:46.989648Z","iopub.execute_input":"2022-05-26T02:45:46.990021Z","iopub.status.idle":"2022-05-26T02:45:47.351231Z","shell.execute_reply.started":"2022-05-26T02:45:46.989984Z","shell.execute_reply":"2022-05-26T02:45:47.34989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Close'].plot(grid=True, figsize=(12,8))","metadata":{"papermill":{"duration":0.437771,"end_time":"2022-05-24T12:30:40.462417","exception":false,"start_time":"2022-05-24T12:30:40.024646","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.353032Z","iopub.execute_input":"2022-05-26T02:45:47.353401Z","iopub.status.idle":"2022-05-26T02:45:47.668111Z","shell.execute_reply.started":"2022-05-26T02:45:47.353353Z","shell.execute_reply":"2022-05-26T02:45:47.667121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df)","metadata":{"papermill":{"duration":0.165314,"end_time":"2022-05-24T12:30:41.060151","exception":false,"start_time":"2022-05-24T12:30:40.894837","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.66956Z","iopub.execute_input":"2022-05-26T02:45:47.669816Z","iopub.status.idle":"2022-05-26T02:45:47.68848Z","shell.execute_reply.started":"2022-05-26T02:45:47.669771Z","shell.execute_reply":"2022-05-26T02:45:47.687377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def c_chart(data,label):\n    # Thanks to https://www.kaggle.com/code/fangya/cryptocurrency-data-visualization-arima\n    candlestick = go.Figure(data = [go.Candlestick(x=data.index,\n                                                   open = data['Open'], \n                                                   high = data['High'], \n                                                   low = data['Low'], \n                                                   close = data['Close'])])\n    candlestick.update_xaxes(title_text = 'Time',\n                             rangeslider_visible = True)\n\n    candlestick.update_layout(\n    title = {\n            'text': '{:} Candelstick Chart'.format(label),\n            \"y\":0.8,\n            \"x\":0.5,\n            'xanchor': 'center',\n            'yanchor': 'top'})\n\n    candlestick.update_yaxes(title_text = 'Price in USD', ticksuffix = '$')\n    return candlestick","metadata":{"papermill":{"duration":0.158829,"end_time":"2022-05-24T12:30:41.366393","exception":false,"start_time":"2022-05-24T12:30:41.207564","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.69039Z","iopub.execute_input":"2022-05-26T02:45:47.690645Z","iopub.status.idle":"2022-05-26T02:45:47.70082Z","shell.execute_reply.started":"2022-05-26T02:45:47.690611Z","shell.execute_reply":"2022-05-26T02:45:47.69967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nbtc_candle=c_chart(df, label=\"BTC Price\")\nbtc_candle.show()","metadata":{"papermill":{"duration":0.308145,"end_time":"2022-05-24T12:30:41.819038","exception":false,"start_time":"2022-05-24T12:30:41.510893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.702209Z","iopub.execute_input":"2022-05-26T02:45:47.702977Z","iopub.status.idle":"2022-05-26T02:45:47.865363Z","shell.execute_reply.started":"2022-05-26T02:45:47.702858Z","shell.execute_reply":"2022-05-26T02:45:47.864722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_stationarity(series):\n    # Thanks to https://machinelearningmastery.com/time-series-data-stationary-python/\n\n    result = adfuller(series.values)\n\n    print('ADF Statistic: %f' % result[0])\n    print('p-value: %f' % result[1])\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t%s: %.3f' % (key, value))\n\n    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n        print(\"\\u001b[32mStationary\\u001b[0m\")\n    else:\n        print(\"\\x1b[31mNon-stationary\\x1b[0m\")","metadata":{"papermill":{"duration":0.181482,"end_time":"2022-05-24T12:30:42.811901","exception":false,"start_time":"2022-05-24T12:30:42.630419","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.866538Z","iopub.execute_input":"2022-05-26T02:45:47.867536Z","iopub.status.idle":"2022-05-26T02:45:47.875015Z","shell.execute_reply.started":"2022-05-26T02:45:47.867498Z","shell.execute_reply":"2022-05-26T02:45:47.873971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stationarity check\ncheck_stationarity(df['Close'])","metadata":{"papermill":{"duration":0.206532,"end_time":"2022-05-24T12:30:43.186037","exception":false,"start_time":"2022-05-24T12:30:42.979505","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.876429Z","iopub.execute_input":"2022-05-26T02:45:47.876767Z","iopub.status.idle":"2022-05-26T02:45:47.933646Z","shell.execute_reply.started":"2022-05-26T02:45:47.876734Z","shell.execute_reply":"2022-05-26T02:45:47.93277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stationarity check of the first difference of time series\ncheck_stationarity(df['Close'].diff().dropna())","metadata":{"papermill":{"duration":0.205936,"end_time":"2022-05-24T12:30:43.606988","exception":false,"start_time":"2022-05-24T12:30:43.401052","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.935336Z","iopub.execute_input":"2022-05-26T02:45:47.935846Z","iopub.status.idle":"2022-05-26T02:45:47.97702Z","shell.execute_reply.started":"2022-05-26T02:45:47.935799Z","shell.execute_reply":"2022-05-26T02:45:47.976164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stationarity check of the second difference of time series\ncheck_stationarity(df['Close'].diff().diff().dropna())","metadata":{"papermill":{"duration":0.210011,"end_time":"2022-05-24T12:30:44.060186","exception":false,"start_time":"2022-05-24T12:30:43.850175","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:47.978586Z","iopub.execute_input":"2022-05-26T02:45:47.979122Z","iopub.status.idle":"2022-05-26T02:45:48.022441Z","shell.execute_reply.started":"2022-05-26T02:45:47.979075Z","shell.execute_reply":"2022-05-26T02:45:48.021573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, it is necessary to model the first difference of the series:","metadata":{"execution":{"iopub.execute_input":"2022-05-19T06:54:31.590261Z","iopub.status.busy":"2022-05-19T06:54:31.589933Z","iopub.status.idle":"2022-05-19T06:54:31.596124Z","shell.execute_reply":"2022-05-19T06:54:31.594909Z","shell.execute_reply.started":"2022-05-19T06:54:31.590231Z"},"papermill":{"duration":0.164844,"end_time":"2022-05-24T12:30:44.441139","exception":false,"start_time":"2022-05-24T12:30:44.276295","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df['Close_diff'] = df['Close'].diff()\ndf = df.dropna()\ndf","metadata":{"papermill":{"duration":0.193057,"end_time":"2022-05-24T12:30:44.79792","exception":false,"start_time":"2022-05-24T12:30:44.604863","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:48.024236Z","iopub.execute_input":"2022-05-26T02:45:48.02477Z","iopub.status.idle":"2022-05-26T02:45:48.067665Z","shell.execute_reply.started":"2022-05-26T02:45:48.024722Z","shell.execute_reply":"2022-05-26T02:45:48.066723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.5. Identification of seasonality <a class=\"anchor\" id=\"3.5\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.167909,"end_time":"2022-05-24T12:30:45.131795","exception":false,"start_time":"2022-05-24T12:30:44.963886","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Get seasonality of the time series\ndecomp = seasonal_decompose(df.Close)\nfig = decomp.plot()\nfig.set_size_inches((12, 10))\nfig.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":1.227249,"end_time":"2022-05-24T12:30:46.524741","exception":false,"start_time":"2022-05-24T12:30:45.297492","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:48.069502Z","iopub.execute_input":"2022-05-26T02:45:48.070054Z","iopub.status.idle":"2022-05-26T02:45:49.053833Z","shell.execute_reply.started":"2022-05-26T02:45:48.070004Z","shell.execute_reply":"2022-05-26T02:45:49.053129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get seasonality of last months (Dec 2021) of the time series\ndecomposition = seasonal_decompose(df.tail(30).Close)\nfig = decomposition.plot()\nfig.set_size_inches((12, 10))\nfig.tight_layout()\nplt.grid(True)\nplt.show()","metadata":{"papermill":{"duration":1.023122,"end_time":"2022-05-24T12:30:47.721944","exception":false,"start_time":"2022-05-24T12:30:46.698822","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:49.055193Z","iopub.execute_input":"2022-05-26T02:45:49.055579Z","iopub.status.idle":"2022-05-26T02:45:49.768689Z","shell.execute_reply.started":"2022-05-26T02:45:49.055528Z","shell.execute_reply":"2022-05-26T02:45:49.767869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tsfresh_features(data):\n    # Get statistic features using library TSFRESH \n    # Thanks to https://www.kaggle.com/code/vbmokin/btc-growth-forecasting-with-advanced-fe-for-ohlc\n    \n    data = data.reset_index(drop=False).reset_index(drop=False)\n    \n    # Extract features\n    extracted_features = extract_features(data, column_id=\"Date\", column_sort=\"Date\")\n    \n    # Drop features with NaN\n    extracted_features_clean = extracted_features.dropna(axis=1, how='all').reset_index(drop=True)\n    \n    # Drop features with constants\n    cols_std_zero  = []\n    for col in extracted_features_clean.columns:\n        if extracted_features_clean[col].std()==0:\n            cols_std_zero.append(col)\n    extracted_features_clean = extracted_features_clean.drop(columns = cols_std_zero)\n\n    extracted_features_clean['Date'] = data['Date']   # For the merging\n    \n    return extracted_features_clean","metadata":{"papermill":{"duration":0.189711,"end_time":"2022-05-24T12:30:49.492978","exception":false,"start_time":"2022-05-24T12:30:49.303267","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:49.770279Z","iopub.execute_input":"2022-05-26T02:45:49.770753Z","iopub.status.idle":"2022-05-26T02:45:49.779949Z","shell.execute_reply.started":"2022-05-26T02:45:49.770708Z","shell.execute_reply":"2022-05-26T02:45:49.779109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# FE with TSFRESH\nextracted_features_clean = get_tsfresh_features(df[['Close']])\nextracted_features_clean","metadata":{"papermill":{"duration":26.259328,"end_time":"2022-05-24T12:31:15.929546","exception":false,"start_time":"2022-05-24T12:30:49.670218","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:45:49.781505Z","iopub.execute_input":"2022-05-26T02:45:49.781872Z","iopub.status.idle":"2022-05-26T02:46:17.724963Z","shell.execute_reply.started":"2022-05-26T02:45:49.781829Z","shell.execute_reply":"2022-05-26T02:46:17.72368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features_clean.describe()","metadata":{"papermill":{"duration":0.322935,"end_time":"2022-05-24T12:31:16.43151","exception":false,"start_time":"2022-05-24T12:31:16.108575","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.732749Z","iopub.execute_input":"2022-05-26T02:46:17.733107Z","iopub.status.idle":"2022-05-26T02:46:17.871078Z","shell.execute_reply.started":"2022-05-26T02:46:17.733074Z","shell.execute_reply":"2022-05-26T02:46:17.870016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracted features by TSFRESH with cleaning\nextracted_features_clean.columns.tolist()","metadata":{"papermill":{"duration":0.219833,"end_time":"2022-05-24T12:31:16.833007","exception":false,"start_time":"2022-05-24T12:31:16.613174","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.872313Z","iopub.execute_input":"2022-05-26T02:46:17.872539Z","iopub.status.idle":"2022-05-26T02:46:17.880345Z","shell.execute_reply.started":"2022-05-26T02:46:17.872511Z","shell.execute_reply":"2022-05-26T02:46:17.879327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all features\ndf = pd.merge(df, extracted_features_clean, how='left', on='Date')\ndf","metadata":{"papermill":{"duration":0.24411,"end_time":"2022-05-24T12:31:17.270009","exception":false,"start_time":"2022-05-24T12:31:17.025899","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.88208Z","iopub.execute_input":"2022-05-26T02:46:17.883636Z","iopub.status.idle":"2022-05-26T02:46:17.937916Z","shell.execute_reply.started":"2022-05-26T02:46:17.883577Z","shell.execute_reply":"2022-05-26T02:46:17.936737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"papermill":{"duration":0.202982,"end_time":"2022-05-24T12:31:17.672194","exception":false,"start_time":"2022-05-24T12:31:17.469212","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.939621Z","iopub.execute_input":"2022-05-26T02:46:17.939877Z","iopub.status.idle":"2022-05-26T02:46:17.946103Z","shell.execute_reply.started":"2022-05-26T02:46:17.939845Z","shell.execute_reply":"2022-05-26T02:46:17.945147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_add_features(df_feat):\n    # FE for data as row of DataFrame\n    # Thanks to https://www.kaggle.com/code/vbmokin/g-research-crypto-forecasting-baseline-fe\n    \n    # Two new features from the competition tutorial\n    df_feat['Upper_Shadow'] = df_feat['High'] - np.maximum(df_feat['Close'], df_feat['Open'])\n    df_feat['Lower_Shadow'] = np.minimum(df_feat['Close'], df_feat['Open']) - df_feat['Low']\n    \n    # Thanks to https://www.kaggle.com/code1110/gresearch-simple-lgb-starter\n    df_feat['lower_shadow'] = np.minimum(df_feat['Close'], df_feat['Open']) - df_feat['Low']\n    df_feat['high2low'] = (df_feat['High'] / df_feat['Low']).replace([np.inf, -np.inf, np.nan], 0.)\n    \n    return df_feat","metadata":{"papermill":{"duration":0.205598,"end_time":"2022-05-24T12:31:18.813824","exception":false,"start_time":"2022-05-24T12:31:18.608226","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.947935Z","iopub.execute_input":"2022-05-26T02:46:17.948945Z","iopub.status.idle":"2022-05-26T02:46:17.959013Z","shell.execute_reply.started":"2022-05-26T02:46:17.948889Z","shell.execute_reply":"2022-05-26T02:46:17.95777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TASK :** It is proposed to experiment with FE : add new features and modify existing ones","metadata":{"papermill":{"duration":0.186931,"end_time":"2022-05-24T12:31:19.193777","exception":false,"start_time":"2022-05-24T12:31:19.006846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# FE - add features\ndf = get_add_features(df)\ndf","metadata":{"papermill":{"duration":0.233568,"end_time":"2022-05-24T12:31:19.611721","exception":false,"start_time":"2022-05-24T12:31:19.378153","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:17.960853Z","iopub.execute_input":"2022-05-26T02:46:17.961526Z","iopub.status.idle":"2022-05-26T02:46:18.014909Z","shell.execute_reply.started":"2022-05-26T02:46:17.961477Z","shell.execute_reply":"2022-05-26T02:46:18.013765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drawing plot with Plotly\nfig = px.line(df, x=\"Date\", y=\"Close\", \n              title=f\"Investigation of dates of anomalous changes in the cryptocurrency rate\", \n              log_y=False,template='gridon',width=800, height=600)\nfig.show()","metadata":{"papermill":{"duration":0.512583,"end_time":"2022-05-24T12:31:21.510154","exception":false,"start_time":"2022-05-24T12:31:20.997571","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.017243Z","iopub.execute_input":"2022-05-26T02:46:18.017591Z","iopub.status.idle":"2022-05-26T02:46:18.313529Z","shell.execute_reply.started":"2022-05-26T02:46:18.017546Z","shell.execute_reply":"2022-05-26T02:46:18.312686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Synthesis dataframe with anomalous dates for Facebook Prophet\nanomalous_dates = ['2021-01-08', '2021-01-27', '2021-04-13', '2021-07-20',\n                   '2021-09-06', '2021-09-29', '2021-11-08', '2021-12-17']\nholidays_df = pd.DataFrame(columns = ['ds', 'lower_window', 'upper_window', 'prior_scale'])\nholidays_df['ds'] = anomalous_dates\nholidays_df['holiday'] = 'anomalous_dates'\nholidays_df['lower_window'] = 0\nholidays_df['upper_window'] = 0\nholidays_df['prior_scale'] = 10\nholidays_df","metadata":{"papermill":{"duration":0.298523,"end_time":"2022-05-24T12:31:22.03914","exception":false,"start_time":"2022-05-24T12:31:21.740617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.315159Z","iopub.execute_input":"2022-05-26T02:46:18.316266Z","iopub.status.idle":"2022-05-26T02:46:18.337018Z","shell.execute_reply.started":"2022-05-26T02:46:18.316208Z","shell.execute_reply":"2022-05-26T02:46:18.336104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_with_anomalies(df, cols_y_list, cols_y_list_name, dates_x, anomalous_dates, log_y=False):\n    # Thanks to https://www.kaggle.com/vbmokin/covid-in-ua-prophet-with-4-nd-seasonality\n    # Draws a plot with title - the features cols_y_list (y) and dates_x (x) from the dataframe df\n    # and with vertical lines in the dates from the list anomalous_dates\n    # with the length between the minimum and maximum of feature cols_y_list[0]\n    # with log_y = False or True\n    # cols_y_list - dictionary of the names of cols from cols_y_list (keys - name of feature, value - it's name for the plot legend), \n    # name of cols_y_list[0] is the title of the all plot\n    \n    fig = px.line(df, x=dates_x, y=cols_y_list[0], title=cols_y_list_name[cols_y_list[0]], log_y=log_y, template='gridon',width=800, height=600)\n    y_max = df[cols_y_list[0]].max()\n    for i in range(len(cols_y_list)-1):\n        fig.add_trace(go.Scatter(x=df[dates_x], y=df[cols_y_list[i+1]], mode='lines', name=cols_y_list_name[cols_y_list[i+1]]))\n        max_i = df[cols_y_list[i+1]].max()\n        y_max = max_i if max_i > y_max else y_max\n    \n    y_min = min(df[cols_y_list[0]].min(),0)\n    for i in range(len(anomalous_dates)):\n        anomal_date = anomalous_dates[i]\n        #print(anomal_date, y_min, y_max)\n        fig.add_shape(dict(type=\"line\", x0=anomal_date, y0=y_min, x1=anomal_date, y1=y_max, line=dict(color=\"red\", width=1)))\n    fig.show()","metadata":{"papermill":{"duration":0.282732,"end_time":"2022-05-24T12:31:22.573293","exception":false,"start_time":"2022-05-24T12:31:22.290561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.338443Z","iopub.execute_input":"2022-05-26T02:46:18.33947Z","iopub.status.idle":"2022-05-26T02:46:18.350804Z","shell.execute_reply.started":"2022-05-26T02:46:18.33942Z","shell.execute_reply":"2022-05-26T02:46:18.349966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw plot\nplot_with_anomalies(df, [\"Close\"], \n                    {\"Close\" : f\"Anomalous dates for {cryptocurrency}\"}, \n                    'Date', anomalous_dates, False)","metadata":{"papermill":{"duration":0.389032,"end_time":"2022-05-24T12:31:23.217076","exception":false,"start_time":"2022-05-24T12:31:22.828044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.35261Z","iopub.execute_input":"2022-05-26T02:46:18.353402Z","iopub.status.idle":"2022-05-26T02:46:18.470116Z","shell.execute_reply.started":"2022-05-26T02:46:18.353346Z","shell.execute_reply":"2022-05-26T02:46:18.469123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drawing plot with Plotly\nfig = px.line(df, x=\"Date\", y=\"Close_diff\", \n              title=f\"Investigation of dates of anomalous changes in the first difference of the cryptocurrency rate\", \n              log_y=False,template='gridon',width=800, height=600)\nfig.show()","metadata":{"papermill":{"duration":0.374752,"end_time":"2022-05-24T12:31:25.020943","exception":false,"start_time":"2022-05-24T12:31:24.646191","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.471761Z","iopub.execute_input":"2022-05-26T02:46:18.472057Z","iopub.status.idle":"2022-05-26T02:46:18.545284Z","shell.execute_reply.started":"2022-05-26T02:46:18.472023Z","shell.execute_reply":"2022-05-26T02:46:18.544613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add new anomalous dates\nanomalous_dates_diff = anomalous_dates.copy()\nanomalous_dates_diff.append('2021-02-08')\nanomalous_dates_diff.append('2021-05-12')\nanomalous_dates_diff.append('2021-09-07')\nanomalous_dates_diff","metadata":{"papermill":{"duration":0.287547,"end_time":"2022-05-24T12:31:25.583975","exception":false,"start_time":"2022-05-24T12:31:25.296428","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.546363Z","iopub.execute_input":"2022-05-26T02:46:18.546598Z","iopub.status.idle":"2022-05-26T02:46:18.554769Z","shell.execute_reply.started":"2022-05-26T02:46:18.54657Z","shell.execute_reply":"2022-05-26T02:46:18.5541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Synthesis dataframe with anomalous dates for Facebook Prophet\nholidays_df_diff = pd.DataFrame(columns = ['ds', 'lower_window', 'upper_window', 'prior_scale'])\nholidays_df_diff['ds'] = anomalous_dates_diff\nholidays_df_diff['holiday'] = 'anomalous_dates_for_difference'\nholidays_df_diff['lower_window'] = 0\nholidays_df_diff['upper_window'] = 0\nholidays_df_diff['prior_scale'] = 10\nholidays_df_diff","metadata":{"papermill":{"duration":0.30606,"end_time":"2022-05-24T12:31:26.16017","exception":false,"start_time":"2022-05-24T12:31:25.85411","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.556512Z","iopub.execute_input":"2022-05-26T02:46:18.556827Z","iopub.status.idle":"2022-05-26T02:46:18.586362Z","shell.execute_reply.started":"2022-05-26T02:46:18.556762Z","shell.execute_reply":"2022-05-26T02:46:18.585687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw plot\nplot_with_anomalies(df, [\"Close_diff\"], \n                    {\"Close_diff\" : f\"Anomalous dates for the first difference of the {cryptocurrency}\"}, \n                    'Date', anomalous_dates_diff, False)","metadata":{"papermill":{"duration":0.394079,"end_time":"2022-05-24T12:31:26.824769","exception":false,"start_time":"2022-05-24T12:31:26.43069","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.588176Z","iopub.execute_input":"2022-05-26T02:46:18.588439Z","iopub.status.idle":"2022-05-26T02:46:18.698967Z","shell.execute_reply.started":"2022-05-26T02:46:18.588407Z","shell.execute_reply":"2022-05-26T02:46:18.697681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Synthesis a new feature in df for anomalous_dates_diff\ndf['Close_diff_anomalous'] = df['Date'].isin(anomalous_dates_diff).astype('int')\ndf","metadata":{"papermill":{"duration":0.293832,"end_time":"2022-05-24T12:31:27.385333","exception":false,"start_time":"2022-05-24T12:31:27.091501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.700357Z","iopub.execute_input":"2022-05-26T02:46:18.7006Z","iopub.status.idle":"2022-05-26T02:46:18.748427Z","shell.execute_reply.started":"2022-05-26T02:46:18.700568Z","shell.execute_reply":"2022-05-26T02:46:18.747194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of anomalous dates\ndf['Close_diff_anomalous'].sum()","metadata":{"papermill":{"duration":0.376042,"end_time":"2022-05-24T12:31:28.048805","exception":false,"start_time":"2022-05-24T12:31:27.672763","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.749951Z","iopub.execute_input":"2022-05-26T02:46:18.750758Z","iopub.status.idle":"2022-05-26T02:46:18.757973Z","shell.execute_reply.started":"2022-05-26T02:46:18.75072Z","shell.execute_reply":"2022-05-26T02:46:18.756984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set COVID parameters\ncovid_feature = 'New_Deaths'  # or \"New_Cases\"\ncountry_covid_feature = f\"USA_{covid_feature}\"\nprint('country_covid_feature =', country_covid_feature)","metadata":{"papermill":{"duration":0.26877,"end_time":"2022-05-24T12:31:29.035102","exception":false,"start_time":"2022-05-24T12:31:28.766332","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.759384Z","iopub.execute_input":"2022-05-26T02:46:18.759707Z","iopub.status.idle":"2022-05-26T02:46:18.770921Z","shell.execute_reply.started":"2022-05-26T02:46:18.759664Z","shell.execute_reply":"2022-05-26T02:46:18.77018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_covid_data(date_start, covid_feature, country='USA'):\n\n    # Thanks https://www.kaggle.com/vbmokin/covid-19-in-70-countries-daily-prophet-forecast\n    # Source: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n    \n    if covid_feature=='New_Cases':\n        file = \"time_series_covid19_confirmed_global.csv\"\n        name_feature = 'Cases'\n    elif covid_feature==\"New_Deaths\":\n        file = \"time_series_covid19_deaths_global.csv\"\n        name_feature = 'Deaths'\n    \n    myfile = requests.get(f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{file}')\n    open('data', 'wb').write(myfile.content)\n    global_df = pd.read_csv('data')\n    \n    if country=='USA':\n        code = 'US'\n    else: code = country\n    \n    try:\n        global_df = global_df[global_df['Country/Region']==code]\n    except:\n        print('Non-existent country code given')\n        return None\n\n    def convert_date_str(df):\n        try:\n            df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n        except:\n            print('_convert_date_str failed with %y, try %Y')\n            df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%Y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n\n    convert_date_str(global_df)\n    \n    global_df2 = global_df.melt(\n        id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], value_vars=global_df.columns[4:], var_name='Date', value_name=name_feature)\n\n    df_covid = global_df2[['Date', name_feature]]\n    df_covid[name_feature] = df_covid[name_feature].astype('int').diff()\n    df_covid = df_covid.fillna(0)\n\n    df_covid['ds'] = pd.to_datetime(df_covid['Date'])\n    df_covid = df_covid[df_covid['ds'] > date_start][['ds', name_feature]].reset_index(drop=True)\n    df_covid.columns = ['Date', country_covid_feature]\n\n    return df_covid\n\ndf_covid = get_covid_data(date_start, covid_feature)","metadata":{"papermill":{"duration":0.57552,"end_time":"2022-05-24T12:31:29.866557","exception":false,"start_time":"2022-05-24T12:31:29.291037","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:18.772208Z","iopub.execute_input":"2022-05-26T02:46:18.772449Z","iopub.status.idle":"2022-05-26T02:46:19.68959Z","shell.execute_reply.started":"2022-05-26T02:46:18.77242Z","shell.execute_reply":"2022-05-26T02:46:19.688561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_covid_data_imputing(df_covid):\n    # Imputing COVID data for USA\n\n    def pd_imputing(df, date1, date2, col):\n        x1 = float(df[df['Date']==date1][col].head(1))\n        x2 = float(df[df['Date']==date2][col].head(1))\n        return (x1+x2)/2\n\n    def df_add(df, date_middle, date1, date2, col=country_covid_feature):\n        # Add imputed COVID data for USA\n        df = df.append({'Date': datetime.strptime(date_middle, '%Y-%m-%d'), col : pd_imputing(df, date1, date2, col=col)}, ignore_index=True)\n        return df\n\n    # Only for USA - the imputing missing data\n    date_anomal = ['2020-10-08', '2020-10-11', '2020-10-12', '2020-10-25']\n    df_covid = df_add(df_covid, '2020-10-08', '2020-10-07', '2020-10-09')\n    df_covid = df_add(df_covid, '2020-10-11', '2020-10-10', '2020-10-13')\n    df_covid = df_add(df_covid, '2020-10-12', '2020-10-11', '2020-10-14')\n    df_covid = df_add(df_covid, '2020-10-25', '2020-10-24', '2020-10-26')\n    df_covid = df_covid.sort_values(by=['Date']).reset_index(drop=True)\n    \n    return df_covid\n\ndf_covid = df_covid_data_imputing(df_covid)\ndf_covid","metadata":{"papermill":{"duration":0.361307,"end_time":"2022-05-24T12:31:30.523302","exception":false,"start_time":"2022-05-24T12:31:30.161995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:19.691155Z","iopub.execute_input":"2022-05-26T02:46:19.691482Z","iopub.status.idle":"2022-05-26T02:46:19.733898Z","shell.execute_reply.started":"2022-05-26T02:46:19.691437Z","shell.execute_reply":"2022-05-26T02:46:19.732739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.merge(df[['Date', 'Close']], df_covid, on = 'Date')\ndata.index = data['Date']\ndata","metadata":{"papermill":{"duration":0.386796,"end_time":"2022-05-24T12:31:31.235314","exception":false,"start_time":"2022-05-24T12:31:30.848518","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:19.736703Z","iopub.execute_input":"2022-05-26T02:46:19.737377Z","iopub.status.idle":"2022-05-26T02:46:19.762688Z","shell.execute_reply.started":"2022-05-26T02:46:19.737258Z","shell.execute_reply":"2022-05-26T02:46:19.761954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_crypto_and_covid(data):\n    # Displays COVID data in USA and cryptocurrency data on one plot\n    \n    def df_minmax_scaler(df):\n        # Data Scalling\n        index_df = df.pop('Date')\n        scaler = MinMaxScaler().fit(df)\n        df = pd.DataFrame(scaler.transform(df), columns = df.columns, index = index_df)\n        return df\n\n    data = df_minmax_scaler(data.copy())\n\n    # Data smoothing and visualization\n    cols_scaled = ['Close_Smoothed_Scaled', country_covid_feature + \"_Smoothed_Scaled\"]\n    data.columns = cols_scaled\n    for col in cols_scaled:\n        data[col] = data[col].rolling(7).mean()\n    data[cols_scaled].plot(lw=4, grid=True, figsize=(12,10))\n\ndraw_crypto_and_covid(data)","metadata":{"papermill":{"duration":0.725651,"end_time":"2022-05-24T12:31:32.285569","exception":false,"start_time":"2022-05-24T12:31:31.559918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:19.763862Z","iopub.execute_input":"2022-05-26T02:46:19.76455Z","iopub.status.idle":"2022-05-26T02:46:20.09873Z","shell.execute_reply.started":"2022-05-26T02:46:19.76451Z","shell.execute_reply":"2022-05-26T02:46:20.09808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the dataset\ndf.to_csv(f'data_of_{cryptocurrency}.csv', index=False)","metadata":{"papermill":{"duration":0.453353,"end_time":"2022-05-24T12:31:32.970153","exception":false,"start_time":"2022-05-24T12:31:32.5168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.100046Z","iopub.execute_input":"2022-05-26T02:46:20.10045Z","iopub.status.idle":"2022-05-26T02:46:20.168617Z","shell.execute_reply.started":"2022-05-26T02:46:20.100419Z","shell.execute_reply":"2022-05-26T02:46:20.167358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Illustration of number transformations in the columns:\n# \"Close\" -> \"Close_diff\" -> \"Target\" -> \"Close_diff_pred\" -> \"Close_pred\"\n# Get target and the result of the forecasting\nforecasting_days_example = 3\ndf_example = pd.DataFrame({'Close':[1, 2, 4, 8, 15, 25], 'Day': [0, 1, 2, 3, 4, 5]})\ndf_example['Close_diff'] = df_example['Close'].diff()\ndf_example['target'] = df_example['Close_diff'].shift(-forecasting_days_example)\ndf_example['target_pred'] = df_example['target'].copy()   # Ideal forecasting result\nprint(f'Simulation of the result of ideal forecasting the \"target_pred\" for {forecasting_days_example} days')\ndisplay(df_example[['Day', 'Close', 'Close_diff', 'target', 'target_pred']])\n\n# Get inverse target\nprint('\\nSimulation of the recovering predicted values \"Close_pred\" from the \"target_pred\"')\ndf_example['Close_diff_pred_shifted'] = df_example['target_pred'].shift(forecasting_days_example)\n\n# Let's create an intermediate feature to make it easier to explain the transformation\ntemp_column_name = f'Close_diff_pred_shifted_with_Close'  # Intermediate feature for transformations \ndf_example[temp_column_name] = df_example['Close_diff_pred_shifted'].copy()\ndf_example.loc[forecasting_days_example, temp_column_name] = df_example.loc[forecasting_days_example,'Close']\ndf_example['Close_pred'] = np.concatenate((df_example['Close'].tolist()[:forecasting_days_example], \n                                           np.cumsum(df_example[temp_column_name].values[forecasting_days_example:], dtype=float)))\ndf_example['Close_pred'] = df_example['Close_pred'].astype('int')\ndisplay(df_example[['Day', 'Close', 'Close_diff', 'target', 'target_pred', 'Close_diff_pred_shifted', temp_column_name, 'Close_pred']])","metadata":{"papermill":{"duration":0.274755,"end_time":"2022-05-24T12:31:34.186829","exception":false,"start_time":"2022-05-24T12:31:33.912074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.170449Z","iopub.execute_input":"2022-05-26T02:46:20.170845Z","iopub.status.idle":"2022-05-26T02:46:20.217734Z","shell.execute_reply.started":"2022-05-26T02:46:20.170765Z","shell.execute_reply":"2022-05-26T02:46:20.216631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cut_data(df, y, num_start, num_end):\n    # Cutting dataframe df and array or list for [num_start, num_end-1]        \n    df2 = df[num_start:(num_end+1)]\n    y2 = y[num_start:(num_end+1)] if y is not None else None\n    return df2, y2","metadata":{"papermill":{"duration":0.240302,"end_time":"2022-05-24T12:31:35.10219","exception":false,"start_time":"2022-05-24T12:31:34.861888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.219167Z","iopub.execute_input":"2022-05-26T02:46:20.219432Z","iopub.status.idle":"2022-05-26T02:46:20.224491Z","shell.execute_reply.started":"2022-05-26T02:46:20.219401Z","shell.execute_reply":"2022-05-26T02:46:20.22386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_target_mf(df, forecasting_days, col='Close'):\n    # Get target as difference of the df[col] \n    # Returns target which is shifted for forecasting_days days in the dataframe df\n    # \"Close\" -> \"Close_diff\" -> \"Target\" \n    col_diff = f\"{col}_diff\"\n    df[col_diff] = df['Close'].diff()\n    df['target'] = df[col_diff].shift(-forecasting_days)\n    df = df.drop(columns=[col_diff]).dropna()\n    \n    return df","metadata":{"papermill":{"duration":0.232925,"end_time":"2022-05-24T12:31:35.559008","exception":false,"start_time":"2022-05-24T12:31:35.326083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.225516Z","iopub.execute_input":"2022-05-26T02:46:20.225734Z","iopub.status.idle":"2022-05-26T02:46:20.24054Z","shell.execute_reply.started":"2022-05-26T02:46:20.225707Z","shell.execute_reply":"2022-05-26T02:46:20.239697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_test_ts(df, forecasting_days, target='Close'):\n    # Get training, validation and test datasets with target for Time Series models\n    \n    # Data prepairing\n    df = df.dropna(how=\"any\").reset_index(drop=True)\n    df = df[['Date', 'Close']]\n    df.columns = ['ds', 'y']        \n    y = None\n\n    # Data smoothing\n#     df.index = df.ds\n#     df = df.drop(columns=['ds'])\n#     df['y'] = df['y'].rolling(7).mean()\n#     df = df.dropna().reset_index(drop=False)\n    \n    N = len(df)\n    train, _ = cut_data(df, y, 0, N-2*forecasting_days-1)\n    valid, _ = cut_data(df, y, N-2*forecasting_days, N-forecasting_days-1)\n    test, _ = cut_data(df, y, N-forecasting_days, N)\n    \n    # Train+valid - for optimal model training\n    train_valid = pd.concat([train, valid])\n\n    print(f'Origin dataset has {len(df)} rows and {len(df.columns)} features')\n    print(f'Get training dataset with {len(train)} rows')\n    print(f'Get validation dataset with {len(valid)} rows')\n    print(f'Get test dataset with {len(test)} rows')\n    \n    return train, valid, test, train_valid","metadata":{"papermill":{"duration":0.238826,"end_time":"2022-05-24T12:31:36.022024","exception":false,"start_time":"2022-05-24T12:31:35.783198","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.241731Z","iopub.execute_input":"2022-05-26T02:46:20.242265Z","iopub.status.idle":"2022-05-26T02:46:20.261887Z","shell.execute_reply.started":"2022-05-26T02:46:20.242221Z","shell.execute_reply":"2022-05-26T02:46:20.260943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_valid_test_mf(df, forecasting_days, target='target'):\n    # Get training, validation and test datasets with target for multi-features ML models\n    \n    df = df.drop(columns = ['Date']).dropna(how=\"any\").reset_index(drop=True)\n    \n    # Save and drop target        \n    y = df.pop(target)\n\n    # Get starting points for the recovering \"Close\" from \"Close_diff_shigted\"\n    N = len(df)\n    #print(f\"Total - {N}, Valid start index = {N-forecasting_days-1}, Test start index = {N-1}\")\n    start_points = {'valid_start_point' : df.loc[N-forecasting_days-1, 'Close'],\n                    'test_start_point' : df.loc[N-1, 'Close']}\n\n    # Standartization data\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n    \n    \n    train, ytrain = cut_data(df.copy(), y, 0, N-2*forecasting_days-1)\n    valid, yvalid = cut_data(df.copy(), y, N-2*forecasting_days, N-forecasting_days-1)\n    test, ytest = cut_data(df.copy(), y, N-forecasting_days, N)\n\n\n    # Train+valid - for optimal model training\n    train_valid = pd.concat([train, valid])\n    y_train_valid = pd.concat([ytrain, yvalid])\n\n    print(f'Origin dataset has {len(df)} rows and {len(df.columns)} features')\n    print(f'Get training dataset with {len(train)} rows')\n    print(f'Get validation dataset with {len(valid)} rows')\n    print(f'Get test dataset with {len(test)} rows')\n    \n    return train, ytrain, valid, yvalid, test, ytest, train_valid, y_train_valid, start_points","metadata":{"papermill":{"duration":0.236836,"end_time":"2022-05-24T12:31:36.486823","exception":false,"start_time":"2022-05-24T12:31:36.249987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.26523Z","iopub.execute_input":"2022-05-26T02:46:20.265846Z","iopub.status.idle":"2022-05-26T02:46:20.279736Z","shell.execute_reply.started":"2022-05-26T02:46:20.265767Z","shell.execute_reply":"2022-05-26T02:46:20.278815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This section provides examples of identifying the following models (but the list goes on):\n* Facebook Prophet \n* ARIMA (and AutoARIMA)\n* Linear Regression\n* KNeighbors Regressor\n* Support Vector Machines\n* Linear SVR\n* Random Forest Regressor\n* Bagging Regressor\n* XGB Regressor\n* MLP Regressor\n\nFB Prophet and ARIMA models have a slightly different data format, while other Machine Learning (ML) models have the same data, so it is easy to increase their number.\n\nClassic model XGBoost have a special format, but this notebook  uses its simplified version, which work in a data format similar to the models of the Sklearn library.\n\nModels based on neural networks (based on PyTorch or Keras) and ensembles of all these models are more effective, but this will be done later in other notebooks.","metadata":{"papermill":{"duration":0.220381,"end_time":"2022-05-24T12:31:37.37977","exception":false,"start_time":"2022-05-24T12:31:37.159389","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def calc_metrics(type_score, list_true, list_pred):\n    # Calculation score with type=type_score for list_true and list_pred \n    if type_score=='r2_score':\n        score = r2_score(list_true, list_pred)\n    elif type_score=='rmse':\n        score = mean_squared_error(list_true, list_pred, squared=False)\n    elif type_score=='mape':\n        score = mean_absolute_percentage_error(list_true, list_pred)\n    return score","metadata":{"papermill":{"duration":0.239411,"end_time":"2022-05-24T12:31:37.842492","exception":false,"start_time":"2022-05-24T12:31:37.603081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.281004Z","iopub.execute_input":"2022-05-26T02:46:20.28183Z","iopub.status.idle":"2022-05-26T02:46:20.296982Z","shell.execute_reply.started":"2022-05-26T02:46:20.281754Z","shell.execute_reply":"2022-05-26T02:46:20.296088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def result_add_metrics(result, n, y_true, y_pred):\n    # Calculation and addition metrics into dataframe result[n,:]\n    \n    result.loc[n,'r2_score'] = calc_metrics('r2_score', y_true, y_pred)\n    result.loc[n,'rmse'] = calc_metrics('rmse', y_true, y_pred)      # in coins\n    result.loc[n,'mape'] = 100*calc_metrics('mape', y_true, y_pred)  # in %\n    \n    return result","metadata":{"papermill":{"duration":0.233029,"end_time":"2022-05-24T12:31:38.30027","exception":false,"start_time":"2022-05-24T12:31:38.067241","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.298162Z","iopub.execute_input":"2022-05-26T02:46:20.29887Z","iopub.status.idle":"2022-05-26T02:46:20.31123Z","shell.execute_reply.started":"2022-05-26T02:46:20.298831Z","shell.execute_reply":"2022-05-26T02:46:20.310449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results of all models\nresult = pd.DataFrame(columns = ['name_model', 'type_data', 'r2_score', 'rmse', 'mape', 'params', 'ypred'])","metadata":{"papermill":{"duration":0.247194,"end_time":"2022-05-24T12:31:38.765253","exception":false,"start_time":"2022-05-24T12:31:38.518059","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.312466Z","iopub.execute_input":"2022-05-26T02:46:20.313203Z","iopub.status.idle":"2022-05-26T02:46:20.333798Z","shell.execute_reply.started":"2022-05-26T02:46:20.313162Z","shell.execute_reply":"2022-05-26T02:46:20.332428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeling 2021 year only\nif is_Prophet:\n    df2 = df[df.Date.dt.year == 2021]\n    display(df2)","metadata":{"papermill":{"duration":0.262975,"end_time":"2022-05-24T12:31:40.185019","exception":false,"start_time":"2022-05-24T12:31:39.922044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.335523Z","iopub.execute_input":"2022-05-26T02:46:20.336237Z","iopub.status.idle":"2022-05-26T02:46:20.380512Z","shell.execute_reply.started":"2022-05-26T02:46:20.336193Z","shell.execute_reply":"2022-05-26T02:46:20.379755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get datasets\nif is_Prophet:\n    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df2.copy(), forecasting_days, target='Close')","metadata":{"papermill":{"duration":0.23801,"end_time":"2022-05-24T12:31:40.648268","exception":false,"start_time":"2022-05-24T12:31:40.410258","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.38186Z","iopub.execute_input":"2022-05-26T02:46:20.382558Z","iopub.status.idle":"2022-05-26T02:46:20.397578Z","shell.execute_reply.started":"2022-05-26T02:46:20.382517Z","shell.execute_reply":"2022-05-26T02:46:20.396762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prophet_modeling(result, \n                     cryptocurrency, \n                     train, \n                     test, \n                     holidays_df, \n                     period_days,\n                     fourier_order_seasonality,\n                     forecasting_period,\n                     name_model,\n                     type_data):\n    # Performs FB Prophet model training for given train dataset, holidays_df and seasonality_mode\n    # Performs forecasting with period by this model, visualization and error estimation\n    # df - dataframe with real data in the forecasting_period\n    # can be such combinations of parameters: train=train, test=valid or train=train_valid, test=test\n    # Save results into dataframe result\n    \n    # Build Prophet model with parameters and structure \n    model = Prophet(daily_seasonality=False, \n                    weekly_seasonality=False, \n                    yearly_seasonality=False, \n                    changepoint_range=1, \n                    changepoint_prior_scale = 0.5, \n                    holidays=holidays_df, \n                    seasonality_mode = 'multiplicative'\n                   )\n    model.add_seasonality(name='seasonality', period=period_days, \n                          fourier_order=fourier_order_seasonality, \n                          mode = 'multiplicative', prior_scale = 0.5)\n    # Training model for df\n    model.fit(train)\n    \n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period)\n    forecast = model.predict(future)\n    \n    # Draw plot of the values with forecasting data\n    figure = model.plot(forecast, xlabel = 'Date', ylabel = f\"{name_model} for {cryptocurrency}\")\n    \n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    figure_component = model.plot_components(forecast)\n    \n    # Ouput the prediction for the next time on forecasted_days\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(1)\n    forecast[['ds', 'yhat_lower', 'yhat', 'yhat_upper']].tail(forecasting_period)\n    \n    # Forecasting data by the model\n    ypred = forecast['yhat'][-forecasting_period:]\n    \n    # Save results\n    n = len(result)\n    result.loc[n,'name_model'] = f\"Prophet_{name_model}\"\n    result.loc[n,'type_data'] = type_data\n    result.at[n,'params'] = [period_days]+[fourier_order_seasonality]\n    result.at[n,'ypred'] = ypred\n    #result = result_add_metrics(result, n, test['y'], y_pred)\n    \n    return result, ypred","metadata":{"papermill":{"duration":0.244085,"end_time":"2022-05-24T12:31:41.116764","exception":false,"start_time":"2022-05-24T12:31:40.872679","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.399262Z","iopub.execute_input":"2022-05-26T02:46:20.399548Z","iopub.status.idle":"2022-05-26T02:46:20.413605Z","shell.execute_reply.started":"2022-05-26T02:46:20.399513Z","shell.execute_reply":"2022-05-26T02:46:20.412417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Models tuning\nif is_Prophet:\n    for period_days in [4, 5, 7, 14]:\n        for fourier_order_seasonality in [3, 12]:\n            result, _ = prophet_modeling(result, \n                                         cryptocurrency, \n                                         train_ts, \n                                         valid_ts, \n                                         holidays_df, \n                                         period_days,\n                                         fourier_order_seasonality,\n                                         forecasting_days,\n                                         f'{period_days}_days_{fourier_order_seasonality}_order',\n                                         'valid')","metadata":{"papermill":{"duration":32.424702,"end_time":"2022-05-24T12:32:14.225596","exception":false,"start_time":"2022-05-24T12:31:41.800894","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:20.415031Z","iopub.execute_input":"2022-05-26T02:46:20.41547Z","iopub.status.idle":"2022-05-26T02:46:52.20739Z","shell.execute_reply.started":"2022-05-26T02:46:20.415431Z","shell.execute_reply":"2022-05-26T02:46:52.206485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get datasets\nif is_ARIMA:\n    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df2.copy(), forecasting_days, target='Close')","metadata":{"papermill":{"duration":0.299199,"end_time":"2022-05-24T12:32:15.367466","exception":false,"start_time":"2022-05-24T12:32:15.068267","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:52.208712Z","iopub.execute_input":"2022-05-26T02:46:52.208969Z","iopub.status.idle":"2022-05-26T02:46:52.22405Z","shell.execute_reply.started":"2022-05-26T02:46:52.208938Z","shell.execute_reply":"2022-05-26T02:46:52.222736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def acf_pacf_draw(df, lag_num=40, acf=True, pacf=True, title=\"\", ylim=1):\n    # Draw plots named title with ACF and PACF for dataframe df\n    \n    num_plots = 1+int(acf)+int(pacf)\n    fig, ax = plt.subplots(1,num_plots,figsize=(12,6))\n    # 'Original Series'\n    ax[0].plot(df.values.squeeze())\n    \n    if acf:\n        # ACF drawing\n        plot_acf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n        ax[1].set(ylim=(-ylim, ylim))\n        \n        if pacf:\n            # PACF drawing\n            plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[2])\n            ax[2].set(ylim=(-ylim, ylim))\n        \n    elif pacf:\n        # PACF drawing\n        plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n        ax[1].set(ylim=(-ylim, ylim))\n\n    fig.suptitle(title)\n    plt.show()","metadata":{"papermill":{"duration":0.299802,"end_time":"2022-05-24T12:32:16.513728","exception":false,"start_time":"2022-05-24T12:32:16.213926","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:52.22563Z","iopub.execute_input":"2022-05-26T02:46:52.225957Z","iopub.status.idle":"2022-05-26T02:46:52.237003Z","shell.execute_reply.started":"2022-05-26T02:46:52.22591Z","shell.execute_reply":"2022-05-26T02:46:52.235665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # ACF and PACF\n    lag_num = 100\n    acf_pacf_draw(train_ts['y'], lag_num, True, True, 'Original Series')\n    acf_pacf_draw(train_ts['y'].diff().dropna(), lag_num, True, True, '1st Order Differencing')\n    acf_pacf_draw(train_ts['y'].diff().diff().dropna(), lag_num, True, True, '2nd Order Differencing')","metadata":{"papermill":{"duration":2.108014,"end_time":"2022-05-24T12:32:18.898179","exception":false,"start_time":"2022-05-24T12:32:16.790165","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:52.239181Z","iopub.execute_input":"2022-05-26T02:46:52.239542Z","iopub.status.idle":"2022-05-26T02:46:53.869888Z","shell.execute_reply.started":"2022-05-26T02:46:52.239495Z","shell.execute_reply":"2022-05-26T02:46:53.868677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- For the above data, we can see that the time series reaches stationarity with first orders of differencing. Although, it value may be higher, as can be seen from the larger values of the lag.","metadata":{"papermill":{"duration":0.28468,"end_time":"2022-05-24T12:32:19.472286","exception":false,"start_time":"2022-05-24T12:32:19.187606","status":"completed"},"tags":[]}},{"cell_type":"code","source":"d = 1","metadata":{"papermill":{"duration":0.296759,"end_time":"2022-05-24T12:32:20.060415","exception":false,"start_time":"2022-05-24T12:32:19.763656","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:53.871404Z","iopub.execute_input":"2022-05-26T02:46:53.87166Z","iopub.status.idle":"2022-05-26T02:46:53.87883Z","shell.execute_reply.started":"2022-05-26T02:46:53.871628Z","shell.execute_reply":"2022-05-26T02:46:53.877852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **5.2.2. How to find the order of the AR term (p)** <a class=\"anchor\" id=\"5.2.2\"></a>\n\n[Table of Contents](#0.1)\n\nThis information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n\n- The next step is to identify if the model needs any AR terms. We will find out the required number of AR terms by inspecting the **Partial Autocorrelation (PACF) plot**.\n\n\n- **Partial autocorrelation** can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. This way, we will know if that lag is needed in the AR term or not.\n\n\n- Partial autocorrelation of lag (k) of a series is the coefficient of that lag in the autoregression equation of Y.\n\n\n$$Yt = \\alpha0 + \\alpha1 Y{t-1} + \\alpha2 Y{t-2} + \\alpha3 Y{t-3}$$\n\n\n- That is, suppose, if Y_t is the current series and Y_t-1 is the lag 1 of Y, then the partial autocorrelation of lag 3 (Y_t-3) is the coefficient $\\alpha_3$ of Y_t-3 in the above equation.\n\n\n- Now, we should find the number of AR terms. Any autocorrelation in a stationarized series can be rectified by adding enough AR terms. So, we initially take the order of AR term to be equal to as many lags that crosses the significance limit in the PACF plot.\n\n","metadata":{"papermill":{"duration":0.287412,"end_time":"2022-05-24T12:32:20.637435","exception":false,"start_time":"2022-05-24T12:32:20.350023","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# PACF drawing\nif is_ARIMA:\n    acf_pacf_draw(train_ts['y'].diff().dropna(), 30, False, True, '1st Order Differencing', 1)","metadata":{"papermill":{"duration":0.656261,"end_time":"2022-05-24T12:32:21.582245","exception":false,"start_time":"2022-05-24T12:32:20.925984","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:53.880335Z","iopub.execute_input":"2022-05-26T02:46:53.880647Z","iopub.status.idle":"2022-05-26T02:46:54.259609Z","shell.execute_reply.started":"2022-05-26T02:46:53.880616Z","shell.execute_reply":"2022-05-26T02:46:54.258716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = 0","metadata":{"papermill":{"duration":0.305834,"end_time":"2022-05-24T12:32:22.76565","exception":false,"start_time":"2022-05-24T12:32:22.459816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.26117Z","iopub.execute_input":"2022-05-26T02:46:54.262109Z","iopub.status.idle":"2022-05-26T02:46:54.26745Z","shell.execute_reply.started":"2022-05-26T02:46:54.26206Z","shell.execute_reply":"2022-05-26T02:46:54.266341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ACF drawing\nif is_ARIMA:\n    acf_pacf_draw(train_ts['y'].diff().dropna(), 30, True, False, '1st Order Differencing', 1)","metadata":{"papermill":{"duration":0.663101,"end_time":"2022-05-24T12:32:24.332354","exception":false,"start_time":"2022-05-24T12:32:23.669253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.268877Z","iopub.execute_input":"2022-05-26T02:46:54.269385Z","iopub.status.idle":"2022-05-26T02:46:54.589367Z","shell.execute_reply.started":"2022-05-26T02:46:54.269342Z","shell.execute_reply":"2022-05-26T02:46:54.58823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q = 0","metadata":{"papermill":{"duration":0.298407,"end_time":"2022-05-24T12:32:25.507715","exception":false,"start_time":"2022-05-24T12:32:25.209308","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.591463Z","iopub.execute_input":"2022-05-26T02:46:54.592391Z","iopub.status.idle":"2022-05-26T02:46:54.598393Z","shell.execute_reply.started":"2022-05-26T02:46:54.592333Z","shell.execute_reply":"2022-05-26T02:46:54.597085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def arima_fit(df, col, order=(1,1,1)):\n    # ARIMA model fitting for series df[col]\n    \n    model = sm.tsa.arima.ARIMA(df[col].values.squeeze(), order=order)\n    model = model.fit()\n    return model","metadata":{"papermill":{"duration":0.300228,"end_time":"2022-05-24T12:32:26.683959","exception":false,"start_time":"2022-05-24T12:32:26.383731","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.600733Z","iopub.execute_input":"2022-05-26T02:46:54.601132Z","iopub.status.idle":"2022-05-26T02:46:54.611186Z","shell.execute_reply.started":"2022-05-26T02:46:54.601082Z","shell.execute_reply":"2022-05-26T02:46:54.61039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # ARIMA Model tuning\n    model = arima_fit(train_ts, 'y', order=(p,d,q))\n    print(model.summary())","metadata":{"papermill":{"duration":0.370275,"end_time":"2022-05-24T12:32:27.347847","exception":false,"start_time":"2022-05-24T12:32:26.977572","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.612633Z","iopub.execute_input":"2022-05-26T02:46:54.613435Z","iopub.status.idle":"2022-05-26T02:46:54.686395Z","shell.execute_reply.started":"2022-05-26T02:46:54.613383Z","shell.execute_reply":"2022-05-26T02:46:54.685666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # ARIMA model diagnostics\n    fig = model.plot_diagnostics(figsize=(12,10))\n    plt.show()","metadata":{"papermill":{"duration":0.996774,"end_time":"2022-05-24T12:32:29.235997","exception":false,"start_time":"2022-05-24T12:32:28.239223","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:54.687697Z","iopub.execute_input":"2022-05-26T02:46:54.688072Z","iopub.status.idle":"2022-05-26T02:46:55.263852Z","shell.execute_reply.started":"2022-05-26T02:46:54.68804Z","shell.execute_reply":"2022-05-26T02:46:55.262764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_residual_errors(model):\n    # Calculation and drawing the plot residual errors for ARIMA model\n    residuals = pd.DataFrame(model.resid)\n    fig, ax = plt.subplots(1,2, figsize=(12,6))\n    residuals.plot(title=\"Residuals\", ax=ax[0])\n    residuals.plot(kind='kde', title='Density', ax=ax[1])\n    plt.show()","metadata":{"papermill":{"duration":0.302024,"end_time":"2022-05-24T12:32:30.433366","exception":false,"start_time":"2022-05-24T12:32:30.131342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:55.26538Z","iopub.execute_input":"2022-05-26T02:46:55.265637Z","iopub.status.idle":"2022-05-26T02:46:55.272945Z","shell.execute_reply.started":"2022-05-26T02:46:55.265605Z","shell.execute_reply":"2022-05-26T02:46:55.271622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # Plot residual errors\n    get_residual_errors(model)","metadata":{"papermill":{"duration":0.6682,"end_time":"2022-05-24T12:32:31.397777","exception":false,"start_time":"2022-05-24T12:32:30.729577","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:55.274554Z","iopub.execute_input":"2022-05-26T02:46:55.274996Z","iopub.status.idle":"2022-05-26T02:46:55.595881Z","shell.execute_reply.started":"2022-05-26T02:46:55.274939Z","shell.execute_reply":"2022-05-26T02:46:55.594788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def arima_forecasting(result, model, params, name_model, df, type_data):\n    # Data df (validation or test) forecasting on the num days by the model \n    # with params and save metrics to result \n    \n    ypred = model.forecast(steps=len(df))\n    \n    n = len(result)\n    result.loc[n,'name_model'] = name_model\n    result.loc[n,'type_data'] = type_data\n    result.at[n,'params'] = params\n    result.at[n,'ypred'] = ypred\n    #result = result_add_metrics(result, n, df['y'], y_pred)\n    \n    return result","metadata":{"papermill":{"duration":0.307088,"end_time":"2022-05-24T12:32:32.600402","exception":false,"start_time":"2022-05-24T12:32:32.293314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:55.597461Z","iopub.execute_input":"2022-05-26T02:46:55.597968Z","iopub.status.idle":"2022-05-26T02:46:55.604995Z","shell.execute_reply.started":"2022-05-26T02:46:55.597928Z","shell.execute_reply":"2022-05-26T02:46:55.604023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # Valid forecasting and save result\n    result = arima_forecasting(result, model, [p]+[d]+[q], 'ARIMA_manual', valid_ts, 'valid')","metadata":{"papermill":{"duration":0.314995,"end_time":"2022-05-24T12:32:33.22003","exception":false,"start_time":"2022-05-24T12:32:32.905035","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:55.606502Z","iopub.execute_input":"2022-05-26T02:46:55.607825Z","iopub.status.idle":"2022-05-26T02:46:55.622003Z","shell.execute_reply.started":"2022-05-26T02:46:55.607744Z","shell.execute_reply":"2022-05-26T02:46:55.621289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif is_ARIMA:\n    # Automatic tuning of the ARIMA model \n    model_auto = pm.auto_arima(train_ts['y'].values, \n                               start_p=4,        # start p\n                               start_q=4,        # start q\n                               test='adf',       # use adftest to find optimal 'd'\n                               max_p=5, max_q=5, # maximum p and q\n                               m=1,              # frequency of series (1 - No Seasonality)\n                               d=None,           # let model determine 'd'\n                               seasonal=False,   # No Seasonality\n                               start_P=0,        \n                               D=0, \n                               start_Q=0,\n                               trace=True,\n                               error_action='ignore',  \n                               suppress_warnings=False, \n                               stepwise=True     # use the stepwise algorithm outlined in Hyndman and Khandakar (2008) \n                                                 # to identify the optimal model parameters. \n                                                 # The stepwise algorithm can be significantly faster than fitting all \n                                                 # hyper-parameter combinations and is less likely to over-fit the model\n                              )\n\n    print(model_auto.summary())","metadata":{"papermill":{"duration":2.76505,"end_time":"2022-05-24T12:32:37.502198","exception":false,"start_time":"2022-05-24T12:32:34.737148","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:55.624375Z","iopub.execute_input":"2022-05-26T02:46:55.62496Z","iopub.status.idle":"2022-05-26T02:46:57.644499Z","shell.execute_reply.started":"2022-05-26T02:46:55.624914Z","shell.execute_reply":"2022-05-26T02:46:57.643674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # Get orders of the best model from AutoARIMA\n    arima_orders_best = list(model_auto.get_params().get('order'))\n    print(f\"Optimal parameters are {arima_orders_best}\")\n    model_auto = arima_fit(train_ts, 'y', order=(arima_orders_best[0],arima_orders_best[1],arima_orders_best[2]))","metadata":{"papermill":{"duration":0.325603,"end_time":"2022-05-24T12:32:38.186115","exception":false,"start_time":"2022-05-24T12:32:37.860512","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:57.646184Z","iopub.execute_input":"2022-05-26T02:46:57.647438Z","iopub.status.idle":"2022-05-26T02:46:57.670681Z","shell.execute_reply.started":"2022-05-26T02:46:57.647376Z","shell.execute_reply":"2022-05-26T02:46:57.66994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_ARIMA:\n    # Valid forecasting and save result\n    result = arima_forecasting(result, model_auto, arima_orders_best, 'ARIMA_auto', valid_ts, 'valid')","metadata":{"papermill":{"duration":0.318671,"end_time":"2022-05-24T12:32:40.62494","exception":false,"start_time":"2022-05-24T12:32:40.306269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:58.385474Z","iopub.execute_input":"2022-05-26T02:46:58.38572Z","iopub.status.idle":"2022-05-26T02:46:58.395237Z","shell.execute_reply.started":"2022-05-26T02:46:58.38569Z","shell.execute_reply":"2022-05-26T02:46:58.394157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3. Other ML models (Multi-factors models) <a class=\"anchor\" id=\"5.3\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.309715,"end_time":"2022-05-24T12:32:41.239647","exception":false,"start_time":"2022-05-24T12:32:40.929932","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"This section provides examples of identifying the following models (but the list goes on):\n* Linear Regression\n* KNeighbors Regressor\n* Support Vector Machines\n* Linear SVR\n* Random Forest Regressor\n* Bagging Regressor\n* XGB Regressor\n* MLP Regressor\n\nClassic model XGBoost have a special format, but this notebook  uses its simplified version, which work in a data format similar to the models of the Sklearn library.\n\nModels based on neural networks (based on PyTorch or Keras) and ensembles of all these models are more effective, but this will be done later in other notebooks.\n\n**This section - from the notebook [Crypto - BTC : 7 prediction models](https://www.kaggle.com/code/vbmokin/crypto-btc-7-prediction-models)**","metadata":{"papermill":{"duration":0.300522,"end_time":"2022-05-24T12:32:41.84335","exception":false,"start_time":"2022-05-24T12:32:41.542828","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Get datasets\nif is_other_ML:\n    df2 = get_target_mf(df2, forecasting_days, col='Close')\n    train_mf, ytrain_mf, valid_mf, yvalid_mf, test_mf, ytest_mf, train_valid_mf, y_train_valid_mf, starting_point = \\\n                                    get_train_valid_test_mf(df2.copy(), forecasting_days, target='target')","metadata":{"papermill":{"duration":0.330565,"end_time":"2022-05-24T12:32:42.480812","exception":false,"start_time":"2022-05-24T12:32:42.150247","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:58.396659Z","iopub.execute_input":"2022-05-26T02:46:58.396926Z","iopub.status.idle":"2022-05-26T02:46:58.427186Z","shell.execute_reply.started":"2022-05-26T02:46:58.396891Z","shell.execute_reply":"2022-05-26T02:46:58.426493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if is_other_ML:\n    # Set parameters of models\n    models = pd.DataFrame(columns = ['name', 'model', 'param_grid'])\n\n    # Linear Regression\n    n = len(models)\n    models.loc[n, 'name'] = 'Linear Regression'\n    models.at[n, 'model'] = LinearRegression()\n    models.at[n, 'param_grid'] = {'fit_intercept' : [True, False]}\n\n\n    # KNeighbors Regressor\n    n = len(models)\n    models.loc[n, 'name'] = 'KNeighbors Regressor'\n    models.at[n, 'model'] = KNeighborsRegressor()\n    models.at[n, 'param_grid'] = {'n_neighbors': [3, 5, 10, 20, 30],\n                                  'leaf_size': [10, 20, 30]\n                                 }\n\n    # Support Vector Machines\n    n = len(models)\n    models.loc[n, 'name'] = 'Support Vector Machines'\n    models.at[n, 'model'] = SVR()\n    models.at[n, 'param_grid'] = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                                  'C': np.linspace(1, 15, 15),\n                                  'tol': [1e-3, 1e-4]\n                                 }\n\n    # Linear SVC\n    n = len(models)\n    models.loc[n, 'name'] = 'Linear SVR'\n    models.at[n, 'model'] = LinearSVR()\n    models.at[n, 'param_grid'] = {'C': np.linspace(1, 15, 15)}\n\n\n    # Random Forest Classifier\n    n = len(models)\n    models.loc[n, 'name'] = 'Random Forest Regressor'\n    models.at[n, 'model'] = RandomForestRegressor()\n    models.at[n, 'param_grid'] = {'n_estimators': [40, 50, 60, 80], \n                                  'min_samples_split': [30, 40, 50, 60], \n                                  'min_samples_leaf': [10, 12, 15, 20, 50],\n                                  'max_features': ['auto'], \n                                  'max_depth': [3, 4, 5, 6]                   \n                                 }\n\n    # Bagging Classifier\n    n = len(models)\n    models.loc[n, 'name'] = 'Bagging Regressor'\n    models.at[n, 'model'] = BaggingRegressor()\n    models.at[n, 'param_grid'] = {'max_features': np.linspace(0.05, 0.8, 1),\n                                  'n_estimators': [3, 4, 5, 6],\n                                  'warm_start' : [False]\n                                 }\n\n    # XGB Classifier\n    n = len(models)\n    models.loc[n, 'name'] = 'XGB Regressor'\n    models.at[n, 'model'] = xgb.XGBRegressor()\n    models.at[n, 'param_grid'] = {'n_estimators': [50, 70, 90], \n                                  'learning_rate': [0.01, 0.05, 0.1, 0.2],\n                                  'max_depth': [3, 4, 5]\n                                 }\n\n    # MLP Classifier\n    n = len(models)\n    models.loc[n, 'name'] = 'MLP Regressor'\n    models.at[n, 'model'] = MLPRegressor()\n    models.at[n, 'param_grid'] = {'hidden_layer_sizes': [i for i in range(2,5)],\n                                  'solver': ['lbfgs', 'sgd'],\n                                  'learning_rate': ['adaptive'],\n                                  'learning_rate_init': [0.001, 0.01],\n                                  'max_iter': [1000]\n                                 }\nmodels","metadata":{"papermill":{"duration":0.36441,"end_time":"2022-05-24T12:32:44.369898","exception":false,"start_time":"2022-05-24T12:32:44.005488","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:58.435855Z","iopub.execute_input":"2022-05-26T02:46:58.436272Z","iopub.status.idle":"2022-05-26T02:46:58.500994Z","shell.execute_reply.started":"2022-05-26T02:46:58.43624Z","shell.execute_reply":"2022-05-26T02:46:58.499621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_prediction(result, models, train_features, valid_features, train_labels, valid_labels):    \n    # Models training and data prediction for all models from DataFrame models\n    # Saving results for validation dataset into dataframe result\n    \n    def calc_add_score(res, n, type_score, list_true, list_pred, feature_end):\n        # Calculation score with type=type_score for list_true and list_pred \n        # Adding score into res.loc[n,...]\n        res.loc[i, type_score + feature_end] = calc_metrics(type_score, list_true, list_pred)\n        return res\n    \n    # Results\n    model_all = []\n\n    for i in range(len(models)):\n        # Training\n        print(f\"Tuning model '{models.loc[i, 'name']}'\")\n        model = GridSearchCV(models.at[i, 'model'], models.at[i, 'param_grid'])\n        model.fit(train_features, train_labels)\n        model_all.append(model)\n        print(f\"Best parameters: {model.best_params_}\\n\")\n        \n        # Prediction\n        ypred = model.predict(valid_features)\n        \n        # Scoring and saving results into the main dataframe result\n        n = len(result)\n        result.loc[n,'name_model'] = f\"{models.loc[i, 'name']}\"\n        result.loc[n,'type_data'] = \"valid\"\n        result.at[n,'params'] = model.best_params_\n        result.at[n,'ypred'] = ypred\n        #result = result_add_metrics(result, n, valid_labels, valid_pred)\n        \n    return result, model_all","metadata":{"papermill":{"duration":0.324144,"end_time":"2022-05-24T12:32:45.638667","exception":false,"start_time":"2022-05-24T12:32:45.314523","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:58.502905Z","iopub.execute_input":"2022-05-26T02:46:58.50316Z","iopub.status.idle":"2022-05-26T02:46:58.514945Z","shell.execute_reply.started":"2022-05-26T02:46:58.50313Z","shell.execute_reply":"2022-05-26T02:46:58.514041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif is_other_ML:\n    # Models tuning and the forecasting\n    result, model_all = model_prediction(result, models, train_mf, valid_mf, ytrain_mf, yvalid_mf)","metadata":{"papermill":{"duration":377.842417,"end_time":"2022-05-24T12:39:03.782367","exception":false,"start_time":"2022-05-24T12:32:45.93995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:46:58.516677Z","iopub.execute_input":"2022-05-26T02:46:58.51738Z","iopub.status.idle":"2022-05-26T02:53:10.741928Z","shell.execute_reply.started":"2022-05-26T02:46:58.517341Z","shell.execute_reply":"2022-05-26T02:53:10.741052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.4. Choosing the main optimal model and forecasting <a class=\"anchor\" id=\"5.4\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.306427,"end_time":"2022-05-24T12:39:04.402835","exception":false,"start_time":"2022-05-24T12:39:04.096408","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def recovery_prediction(y, starting_point):\n    # Recovering prediction of multi-factors model for shifted col_diff to col in the dataframe df\n    # y has type np.array\n    # starting_point is dictionary with start values for the recovering data\n    # Returns y (np.array) with recovering data\n    \n    return np.insert(y, 0, starting_point).cumsum()[1:]","metadata":{"papermill":{"duration":0.320791,"end_time":"2022-05-24T12:39:05.039192","exception":false,"start_time":"2022-05-24T12:39:04.718401","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.743856Z","iopub.execute_input":"2022-05-26T02:53:10.744119Z","iopub.status.idle":"2022-05-26T02:53:10.748763Z","shell.execute_reply.started":"2022-05-26T02:53:10.744086Z","shell.execute_reply":"2022-05-26T02:53:10.748156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def result_recover_and_metrics(result, df_ts, type_data, start_points):\n    # Recovering prediction: from shifted_Close_diff to Close\n    # Calculation metrics for recovering ypred forecasting for all models in result\n    # ypred real is from df_ts['y']\n    # start points value for the recovering is from dictionary start_points\n    # type_data = 'valid' or 'test'\n\n    for i in range(len(result)):\n        if (result.loc[i, 'type_data']==type_data) and (result.loc[i, 'mape'] is np.nan):\n            ypred = result.loc[i, 'ypred']\n\n            # Recovering ypred for multi-factors models\n            if not (result.loc[i, 'type_model'] in ['Prophet', 'ARIMA']):\n                # Multi-factors model\n                # Get start points value for the recovering\n                start_point_value = start_points['valid_start_point'] if type_data=='valid' else start_points['test_start_point']\n                # Recovering prediction\n                ypred = recovery_prediction(ypred, start_point_value)\n\n            # Calculation metrics\n            result = result_add_metrics(result, i, df_ts['y'], ypred)\n    \n    return result","metadata":{"papermill":{"duration":0.322481,"end_time":"2022-05-24T12:39:05.663547","exception":false,"start_time":"2022-05-24T12:39:05.341066","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.749877Z","iopub.execute_input":"2022-05-26T02:53:10.7504Z","iopub.status.idle":"2022-05-26T02:53:10.767088Z","shell.execute_reply.started":"2022-05-26T02:53:10.750363Z","shell.execute_reply":"2022-05-26T02:53:10.765867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dispay and save all results for validation dataset\nif len(result) > 0:\n    \n    # Get type of each model\n    result['type_model'] = result['name_model'].str.split('_').str[0]\n\n    # Calculation metrics for recovering prediction ypred for validation dataset by all models \n    result = result_recover_and_metrics(result, valid_ts, 'valid', starting_point)\n    display(result[['name_model', 'type_data', 'r2_score', 'rmse', 'mape']].sort_values(by=['type_data', 'mape', 'rmse'], ascending=True))\n    \n    # Save results\n    num_models = len(result[result['type_data']=='valid']['name_model'].unique().tolist())\n    print(f\"Number of models built - {num_models}\")\n    result.to_csv(f'result_of_{num_models}_models_for_forecasting_days_{forecasting_days}.csv')\nelse: \n    print('There are no tuned models!')","metadata":{"papermill":{"duration":0.401246,"end_time":"2022-05-24T12:39:06.371773","exception":false,"start_time":"2022-05-24T12:39:05.970527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.768705Z","iopub.execute_input":"2022-05-26T02:53:10.769115Z","iopub.status.idle":"2022-05-26T02:53:10.850136Z","shell.execute_reply.started":"2022-05-26T02:53:10.769074Z","shell.execute_reply":"2022-05-26T02:53:10.849438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_opt(name_model, params):\n    # Model tuning for the name_model\n    \n    print(name_model)\n    if name_model=='Linear Regression':\n        model = LinearRegression(**params)\n        \n    elif name_model=='KNeighbors Regressor':\n        model = KNeighborsRegressor(**params)\n        \n    elif name_model=='Support Vector Machines':\n        model = SVR(**params)\n        \n    elif name_model=='Linear SVR':\n        model = LinearSVR(**params)\n        \n    elif name_model=='Random Forest Regressor':\n        model = RandomForestRegressor(**params)\n        \n    elif name_model=='Bagging Regressor':\n        model = BaggingRegressor(**params)\n    \n    elif name_model=='MLP Regressor':\n        model = MLPRegressor(**params)\n        \n    elif name_model=='XGB Regressor':\n        model = xgb.XGBRegressor(**params)\n        \n    else: model = None\n        \n    return model","metadata":{"papermill":{"duration":0.317888,"end_time":"2022-05-24T12:39:07.000081","exception":false,"start_time":"2022-05-24T12:39:06.682193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.851228Z","iopub.execute_input":"2022-05-26T02:53:10.851579Z","iopub.status.idle":"2022-05-26T02:53:10.859972Z","shell.execute_reply.started":"2022-05-26T02:53:10.851541Z","shell.execute_reply":"2022-05-26T02:53:10.858741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_params_optimal_model(result, main_metrics):\n    # Get parameters of the optimal model from dataframe result by main_metrics\n\n    # Set the data type to float (just in case)\n    result[main_metrics] = result[main_metrics].astype('float')\n    \n    # Choose the optimal model\n    opt_result = result[result['type_data']=='valid'].reset_index(drop=True)\n    if main_metrics=='r2_score':\n        opt_model = opt_result.nlargest(1, main_metrics)\n    else:\n        # 'mape' or 'rmse'\n        opt_model = opt_result.nsmallest(1, main_metrics)\n    display(opt_model[['name_model', 'r2_score', 'rmse', 'mape', 'params']])\n\n    # Get parameters of the optimal model\n    opt_name_model = opt_model['name_model'].tolist()[0]\n    opt_type_model = opt_model['type_model'].tolist()[0]\n    opt_params_model = opt_model['params'].tolist()[0]\n    print(f\"Optimal model is '{opt_name_model}' with parameters {opt_params_model}\")\n    \n    return opt_name_model, opt_type_model, opt_params_model","metadata":{"papermill":{"duration":0.326684,"end_time":"2022-05-24T12:39:07.638596","exception":false,"start_time":"2022-05-24T12:39:07.311912","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.8612Z","iopub.execute_input":"2022-05-26T02:53:10.86144Z","iopub.status.idle":"2022-05-26T02:53:10.878727Z","shell.execute_reply.started":"2022-05-26T02:53:10.861412Z","shell.execute_reply":"2022-05-26T02:53:10.877944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_training_forecasting(result, df, y, test, ytest,  \n                               name_model, type_model, params, type_test='1'):\n    # Model training for df and y\n    # Forecasting ypred\n    # type_model = 'Prophet' or \"ARIMA\" or 'Other ML'\n    # type_test = '1' (with find optimal parameters by GridSearchCV) \n    # type_test = '2' (with optimal parameters - without GridSearchCV)\n    # return params and metrics in the dataframe result\n    \n    if type_model=='Prophet':\n        season_days_optimal = params[0]\n        fourier_order_seasonality_optimal = params[1]\n        model_opt = None\n        _, ypred = prophet_modeling(result, \n                                    cryptocurrency, \n                                    df, \n                                    test, \n                                    holidays_df, \n                                    season_days_optimal,\n                                    fourier_order_seasonality_optimal,\n                                    forecasting_days,\n                                    f'{type_model}_optimal',\n                                    'test')        \n        \n    elif type_model=='ARIMA':\n        season_days_optimal = params[0]\n        fourier_order_seasonality_optimal = params[1]        \n        model_opt = None\n        \n        # Training ARIMA optimal model for training+valid dataset\n        df['y'] = y\n        model_opt = arima_fit(df, 'y', order=(params[0],params[1],params[2]))        \n\n        # Model diagnostics\n        fig = model_opt.plot_diagnostics(figsize=(12,10))\n        plt.show()\n\n        # Plot residual errors\n        get_residual_errors(model_opt)\n\n        # Test forecasting and save result\n        ypred = model_opt.forecast(steps=len(test))        \n\n    else:\n        # Other ML model\n        # Training ML optimal model for training+valid dataset\n        print(f\"Tuning model '{name_model}'\")\n        models_opt_number = models[models['name']==name_model].index.tolist()[0]\n        #print(f\"Model - {models.at[models_opt_number,'model']} with parameters {params}\")\n        if type_test=='1':\n            model_opt = GridSearchCV(models.at[models_opt_number,'model'], models.at[models_opt_number,'param_grid'])\n        else:\n            # type_test=='2'\n            model_opt = get_model_opt(models.at[models_opt_number,'name'], params)\n        model_opt.fit(df, y)\n        \n        # Forecasting\n        ypred = model_opt.predict(test)\n\n        \n    # Scoring and saving results into the dataframe result\n    n = len(result)\n    result.loc[n,'name_model'] = f\"{type_model}_optimal\"\n    result.loc[n,'type_data'] = \"test\"\n    result.at[n,'params'] = params\n    result.at[n,'ypred'] = ypred\n    #result = result_add_metrics(result, n, ytest, ypred)\n    \n    return result, model_opt, ypred","metadata":{"papermill":{"duration":0.332731,"end_time":"2022-05-24T12:39:08.285037","exception":false,"start_time":"2022-05-24T12:39:07.952306","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.880628Z","iopub.execute_input":"2022-05-26T02:53:10.881044Z","iopub.status.idle":"2022-05-26T02:53:10.90037Z","shell.execute_reply.started":"2022-05-26T02:53:10.880996Z","shell.execute_reply":"2022-05-26T02:53:10.899347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_optimal_model_and_forecasting(result, main_metrics, start_points):\n    # Choosion the optimal model from dataframe result by main_metrics\n    # Tuning optimal model for big dataset train+valid \n    # Test forecasting and drawing it\n    # Returns the optimal model and it's name\n\n    if len(result) > 0:\n        # Get parameters of the optimal model from dataframe result by main_metrics\n        opt_name_model, opt_type_model, opt_params_model = get_params_optimal_model(result, \n                                                                                    main_metrics)\n        # Set datasets for the final tuning and testing by optimal model\n        if (opt_type_model=='Prophet') or (opt_type_model=='ARIMA'):\n            train_valid = train_valid_ts.copy()\n            y_train_valid = train_valid_ts['y'].copy()\n            test = test_ts.copy()\n            ytest = test_ts['y'].copy()\n            \n        else:\n            # Multi-factors ML models\n            train_valid = train_valid_mf.copy()\n            y_train_valid = y_train_valid_mf.copy()\n            test = test_mf.copy()\n            ytest = ytest_mf.copy()\n    \n        # Optimal model training for train+valid and test forecasting\n        result, model_opt, ypred = model_training_forecasting(result, train_valid, y_train_valid,\n                                                              test, ytest,\n                                                              opt_name_model, opt_type_model, \n                                                              opt_params_model, '1')\n        \n        # Calculation metrics for recovering prediction ypred for test dataset by the optimal model\n        result = result_recover_and_metrics(result, test_ts, 'test', start_points)\n        \n        # Drawing plot for prediction for the test data \n        if not ((opt_type_model=='Prophet') or (opt_type_model=='ARIMA')):\n            # Recovery values \"Close\"\n            ytest_plot = recovery_prediction(ytest.values, start_points['test_start_point'])\n            ypred_plot = recovery_prediction(ypred, start_points['test_start_point'])\n        else:\n            ytest_plot = ytest.copy()\n            ypred_plot = ypred.copy()\n            \n        # Drawing \n        plt.figure(figsize=(12,8))\n        x = np.arange(len(ytest_plot))\n        plt.scatter(x, ytest_plot, label = \"Target test data\", color = 'g', s=100)\n        plt.scatter(x, ypred_plot, label = f\"{opt_name_model} forecasting\", color = 'r', s=50)\n        plt.title(f'Forecasting of test data using the \"{opt_name_model}\" model, which is optimal for \"{main_metrics}\" metrics')\n        plt.ylim(0)\n        plt.legend(loc='lower right')\n        plt.grid(True)\n        \n        return opt_name_model","metadata":{"papermill":{"duration":0.325662,"end_time":"2022-05-24T12:39:10.259386","exception":false,"start_time":"2022-05-24T12:39:09.933724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.901941Z","iopub.execute_input":"2022-05-26T02:53:10.902917Z","iopub.status.idle":"2022-05-26T02:53:10.921556Z","shell.execute_reply.started":"2022-05-26T02:53:10.902859Z","shell.execute_reply":"2022-05-26T02:53:10.92071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the optimal model by different metrics\nif len(result) > 0:\n    for valid_metrics in ['r2_score', 'rmse', 'mape']:\n        get_optimal_model_and_forecasting(result, valid_metrics, starting_point)    ","metadata":{"papermill":{"duration":92.211978,"end_time":"2022-05-24T12:40:42.778723","exception":false,"start_time":"2022-05-24T12:39:10.566745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:53:10.923255Z","iopub.execute_input":"2022-05-26T02:53:10.923769Z","iopub.status.idle":"2022-05-26T02:54:43.450008Z","shell.execute_reply.started":"2022-05-26T02:53:10.923717Z","shell.execute_reply":"2022-05-26T02:54:43.448878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training ML optimal model for training+valid dataset\n# Get parameters of the optimal model from dataframe result (without Time Series models) by main_metrics\nmain_metrics = 'r2_score'\nif (len(result) > 0) and (len(models) > 0):\n    result_nonTS = result[(result['type_model']!='Prophet') & (result['type_model']!='ARIMA')].reset_index(drop=True)\n    opt_name_model2, opt_type_model2, opt_params_model2 = get_params_optimal_model(result_nonTS, \n                                                                            main_metrics)\n    \n    result, model_opt, ypred = model_training_forecasting(result, \n                                                          train_valid_mf, \n                                                          y_train_valid_mf,\n                                                          test_mf, \n                                                          ytest_mf,\n                                                          opt_name_model2, \n                                                          opt_type_model2, \n                                                          opt_params_model2, \n                                                          '2')","metadata":{"papermill":{"duration":0.433131,"end_time":"2022-05-24T12:40:44.820765","exception":false,"start_time":"2022-05-24T12:40:44.387634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T02:54:43.451923Z","iopub.execute_input":"2022-05-26T02:54:43.452183Z","iopub.status.idle":"2022-05-26T02:54:43.560987Z","shell.execute_reply.started":"2022-05-26T02:54:43.452152Z","shell.execute_reply":"2022-05-26T02:54:43.559866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All features names\ncoeff = pd.DataFrame(train_valid_mf.columns)\ncoeff.columns = ['feature']","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:05.270455Z","iopub.execute_input":"2022-05-26T05:09:05.270763Z","iopub.status.idle":"2022-05-26T05:09:05.276185Z","shell.execute_reply.started":"2022-05-26T05:09:05.270728Z","shell.execute_reply":"2022-05-26T05:09:05.275289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_fi_coeff(coeff, col, list_new_fi_coeff=None, df_new_fi_coeff=None):\n    # Adds new importance of features as feature col\n    # from list list_new_fi_coeff or dataframe df_new_fi_coeff\n    # to the resulting dataframe coeff with feature names \n    # Missed importance values are replaced by zero\n    \n    if list_new_fi_coeff is not None:\n        df_new_fi_coeff = coeff[['feature']].copy()\n        df_new_fi_coeff[\"score\"] = pd.Series(list_new_fi_coeff)\n    \n    if df_new_fi_coeff is not None:\n        # Rename df_new_fi_coeff\n        df_new_fi_coeff.columns = ['feature', 'score']   # to the plot drawing\n        df_new_fi_coeff[col] = df_new_fi_coeff['score']  # to the merging and saving\n        \n        # Merging dataframes - coeff of all features with new_fi_coeff\n        coeff = coeff.merge(df_new_fi_coeff[['feature', col]], on='feature', how='left').fillna(0)\n        \n        is_score = True\n    else:\n        print(f'Data is absent fol {col}')\n        is_score = False\n        coeff = None\n    \n    return coeff, df_new_fi_coeff, is_score","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:05.347753Z","iopub.execute_input":"2022-05-26T05:09:05.348959Z","iopub.status.idle":"2022-05-26T05:09:05.356716Z","shell.execute_reply.started":"2022-05-26T05:09:05.348892Z","shell.execute_reply":"2022-05-26T05:09:05.355925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importance diagram with SHAP\nif (len(result) > 0) and (len(models) > 0):\n    print('Feature importance diagram with SHAP:')\n    try:\n        # Trees\n        explainer = shap.TreeExplainer(model_opt)\n        shap_values = explainer.shap_values(test_mf)\n        shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n        shap.summary_plot(shap_values, test_mf)\n        \n        # Save permutation feature importance values\n        coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', shap_values)\n    except: \n        try:\n            # Other types of models\n            explainer = shap.KernelExplainer(model_opt.predict, train_valid_mf)\n            shap_values = explainer.shap_values(test_mf)\n            \n            # Plot drawing\n            shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n            shap.summary_plot(shap_values, test_mf)\n            \n            # Get feature importance values from shap_values format\n            # Thanks to https://stackoverflow.com/a/69523421/12301574\n            shap_values_all = pd.DataFrame(shap_values, columns = test_mf.columns)\n            vals = np.abs(shap_values_all.values).mean(0)\n            shap_importance = pd.DataFrame(list(zip(test_mf.columns, vals)),\n                                              columns=['feature','score'])            \n\n            # Saving feature importance values\n            coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', None, shap_importance)            \n            \n        except: \n            is_SHAP_successfully = False\n    \n    if not is_SHAP_successfully:\n        print('Feature importance diagram for this optimal model is not supported in SHAP')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:05.417376Z","iopub.execute_input":"2022-05-26T05:09:05.417977Z","iopub.status.idle":"2022-05-26T05:09:57.518654Z","shell.execute_reply.started":"2022-05-26T05:09:05.417937Z","shell.execute_reply":"2022-05-26T05:09:57.51756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Force plot - Feature importance diagram with SHAP for the certaion row in test_mf\nif (len(result) > 0) and (len(models) > 0):\n    row_number_in_test_mf = 0\n    print('Feature importance diagram as the Force plot with SHAP:')\n    if is_SHAP_successfully:\n        shap.initjs()\n        shap.force_plot(explainer.expected_value, shap_values[0,:], \n                        test_mf.loc[test_mf.index.tolist()[row_number_in_test_mf],:],\n                        feature_names=coeff['feature'].tolist(),\n                        matplotlib=True, show=False)\n        plt.savefig('force_plot.png')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:57.521024Z","iopub.execute_input":"2022-05-26T05:09:57.52148Z","iopub.status.idle":"2022-05-26T05:09:58.312676Z","shell.execute_reply.started":"2022-05-26T05:09:57.521428Z","shell.execute_reply":"2022-05-26T05:09:58.312007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creation and drawing the feature importance diagrams\nif (len(result) > 0) and (len(models) > 0):\n\n    # Coefficients\n    if opt_name_model2=='XGB Regressor':\n        print('Feature importance diagram')\n        # Coef. of the feature with nonzero importance\n        xgb_coeff = pd.DataFrame.from_dict(model_opt.get_booster().get_score(importance_type='weight'), orient='index').reset_index(drop=False)\n        coeff, _, is_score = add_fi_coeff(coeff, 'xgb_fi_coeff', None, xgb_coeff)\n\n        # With the library xgboost\n        fig =  plt.figure(figsize = (15,15))\n        axes = fig.add_subplot(111)\n        xgb.plot_importance(model_opt,ax = axes,height = 0.5)\n        plt.show()\n        plt.close()\n\n    else:\n        # With the library sklearn\n        try:\n            coef_model = model_opt.coef_\n            coeff, coeff_new, is_score = add_fi_coeff(coeff, 'lr_fi_score', coef_model)\n        except:\n            try:\n                coef_model = feature_importances_\n                coeff, coeff_new, is_score = add_fi_coeff(coeff, 'model_fi_score', coef_model)\n            except: \n                print('The importance of the feature could not be obtained')\n                is_score = False\n\n        if is_score:\n            # Plot drawing\n            coeff_non_zero = coeff_new[coeff_new['score']>0]\n            plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n            coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n            plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n            plt.title(\"Feature importance diagram\")\n            plt.axvline(x=0, color=\".5\")\n            plt.xlabel(\"Coefficient values\")\n            plt.subplots_adjust(left=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:58.314021Z","iopub.execute_input":"2022-05-26T05:09:58.314653Z","iopub.status.idle":"2022-05-26T05:09:58.329887Z","shell.execute_reply.started":"2022-05-26T05:09:58.314592Z","shell.execute_reply":"2022-05-26T05:09:58.328921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Permutation feature importance diagram\nif (len(result) > 0) and (len(models) > 0):\n    try:\n        perm_importance = permutation_importance(model_opt, test_mf, ytest_mf)\n        \n        # Save permutation feature importance values\n        coef_model = perm_importance.importances_mean\n        coeff, coeff_new, is_score = add_fi_coeff(coeff, 'perm_fi_score', coef_model)\n        \n        print('Permutation feature importance diagram:') \n        coeff_non_zero = coeff_new[coeff_new['score'].abs()>1e-4]\n        coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n        plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n        plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n        plt.xlabel(\"Permutation Importance\")\n        plt.show()\n        is_perm_importance = True\n    except: print('Permutation feature importance diagram for this optimal model is not supported')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:58.331077Z","iopub.execute_input":"2022-05-26T05:09:58.331324Z","iopub.status.idle":"2022-05-26T05:09:59.431837Z","shell.execute_reply.started":"2022-05-26T05:09:58.331293Z","shell.execute_reply":"2022-05-26T05:09:59.430598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importance diagram with ELI5\nif (len(result) > 0) and (len(models) > 0):\n    try:\n        print('Feature importance diagram with ELI5:')\n        perm = PermutationImportance(model_opt).fit(test_mf,ytest_mf)\n        \n        # Save permutation feature importance values\n        coef_model = perm.feature_importances_  # Feature importances, \n                                                # computed as mean decrease \n                                                # of the score when a feature \n                                                # is permuted (i.e. becomes noise)\n        coeff, _, is_score = add_fi_coeff(coeff, 'eli5_perm_fi_score', coef_model)\n        \n        # Display permutation feature importance values with ELI5\n        display(eli5.show_weights(perm, feature_names = coeff.feature.tolist()))\n        \n    except: print('Feature importance diagram for this optimal model is not supported in ELI5')","metadata":{"execution":{"iopub.status.busy":"2022-05-26T05:09:59.434688Z","iopub.execute_input":"2022-05-26T05:09:59.435058Z","iopub.status.idle":"2022-05-26T05:10:00.152619Z","shell.execute_reply.started":"2022-05-26T05:09:59.435011Z","shell.execute_reply":"2022-05-26T05:10:00.151453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display and saving features importance values\nif coeff.isna().sum().sum()==0:\n    print('Feature importance values:')\n    fi_cols = coeff.columns.tolist()[1:]\n    if len(fi_cols) > 0:\n        coeff = coeff.sort_values(by=fi_cols, ascending=False)\n        display(coeff)\n    coeff.to_csv(f'feature_importance_for_optimal_model_{opt_name_model2}.csv', index=False)","metadata":{"papermill":{"duration":0.33325,"end_time":"2022-05-24T12:40:45.469563","exception":false,"start_time":"2022-05-24T12:40:45.136313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-26T05:17:23.63684Z","iopub.execute_input":"2022-05-26T05:17:23.637227Z","iopub.status.idle":"2022-05-26T05:17:23.672391Z","shell.execute_reply.started":"2022-05-26T05:17:23.63719Z","shell.execute_reply":"2022-05-26T05:17:23.671488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{"papermill":{"duration":0.324885,"end_time":"2022-05-24T12:40:47.411629","exception":false,"start_time":"2022-05-24T12:40:47.086744","status":"completed"},"tags":[]}}]}